{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7SXSDxmWSpzvl3suQ692d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DManiscalco/MMA-Matchups/blob/main/Graph_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Can use a Graph Neural Network if we have data of stats of specific fights (nodes are fighters and edges are fights)"
      ],
      "metadata": {
        "id": "B_4ZF8kHVMbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch_geometric\n",
        "!pip install kagglehub --upgrade"
      ],
      "metadata": {
        "id": "Uz6b97o-yT1N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import torch\n",
        "from torch.utils.data import Dataset  #, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Libraries for the graph model\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "pkzpTFII5neK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppotB5CsVJFP",
        "outputId": "f9ccaa62-950b-403d-c784-62550f9c4b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.csv\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset from kaggle\n",
        "path = kagglehub.dataset_download('calmdownkarm/ufcdataset')\n",
        "\n",
        "# Use $ to keep python variable in the terminal command\n",
        "!ls $path  # make sure there are files in the path as we expect\n",
        "!cp -r $path/* /content/  # move to /content folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file to a pandas df\n",
        "data_csv = pd.read_csv('/content/data.csv')"
      ],
      "metadata": {
        "id": "khEFhgkfWfOk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fight information for the edges\n",
        "fight_info_cols = ['Event_ID', 'Fight_ID', 'Last_round', 'Max_round', 'winby', 'winner', 'B_ID', 'R_ID', 'B_Age', 'R_Age']  # don't include 'Date' for now\n",
        "for col in data_csv.columns:\n",
        "  # Using the below to keep the order of the last round and max round columns\n",
        "  if 'round' in col.lower() and col not in ['Last_round', 'Max_round']:\n",
        "    fight_info_cols.append(col)\n",
        "\n",
        "fight_info_df = data_csv[fight_info_cols]\n",
        "fight_info_df.loc[:, 'winner'] = fight_info_df.apply(lambda x: x['B_ID'] if x['winner'] == 'blue' else (x['R_ID'] if x['winner'] == 'red' else x['winner']), axis=1)\n",
        "fight_info_df = fight_info_df[(fight_info_df['winner'] != 'draw') & (fight_info_df['winner'] != 'no contest')]  # get rid of rows with no contest or draw\n",
        "\n",
        "# Fighter information for the nodes\n",
        "fighter_info_cols = ['B_Height',\t'B_HomeTown',\t'B_ID', 'B_Location', 'B_Name', 'R_Height', 'R_HomeTown', 'R_ID', 'R_Location', 'R_Name']\n",
        "fighter_info_init = data_csv[fighter_info_cols]\n",
        "\n",
        "# Make df of fighter names and information for red and blue\n",
        "fighter_info_red = fighter_info_init[['R_Height', 'R_HomeTown', 'R_ID', 'R_Location', 'R_Name']]\n",
        "fighter_info_blue = fighter_info_init[['B_Height',\t'B_HomeTown',\t'B_ID',\t'B_Location',\t'B_Name']]\n",
        "\n",
        "# Rename the cols to be the same for both dfs\n",
        "fighter_col_names = ['Height', 'HomeTown', 'ID', 'Location', 'Name']\n",
        "fighter_info_red.columns = fighter_col_names\n",
        "fighter_info_blue.columns = fighter_col_names\n",
        "\n",
        "# Concat the cols and drop duplicates\n",
        "fighter_info_concat = pd.concat([fighter_info_blue, fighter_info_red])"
      ],
      "metadata": {
        "id": "-ZkmxaUN54M1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in NaN values - 'Unknown' for string values and average fighter height for unknown height\n",
        "na_fill_values_fighter = {'Height': fighter_info_concat['Height'].mean(), 'HomeTown': 'Parts Unknown', 'Location': 'Parts Unknown'}\n",
        "fighter_info_concat = fighter_info_concat.fillna(value=na_fill_values_fighter).infer_objects(copy=False)\n",
        "\n",
        "# Fill in the NaN values for the fight non-round cols\n",
        "na_fill_values_fight = {'winby': 'UNK', 'B_Age': round(fight_info_df['B_Age'].mean(), 1), 'R_Age': round(fight_info_df['R_Age'].mean(), 1)}\n",
        "fight_info_df = fight_info_df.fillna(value=na_fill_values_fight).infer_objects(copy=False)\n",
        "\n",
        "# Fill in the NaN values for the fight 'round' cols\n",
        "fight_info_df = fight_info_df.fillna(0).infer_objects(copy=False)"
      ],
      "metadata": {
        "id": "Tu3t8hYqMK-d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For fighters, check if there are any duplicates between names and IDs\n",
        "dupe_df = fighter_info_concat.drop_duplicates(subset=['ID'])\n",
        "# dupe_df[dupe_df.duplicated(['Name'], keep=False)]  # uncomment this to show duplicates\n",
        "\n",
        "# Duplicate is Dong Hyun Kim with ID of 455 and 2709 - change one of them\n",
        "fighter_info_concat.loc[fighter_info_concat['ID'] == 2709, 'ID'] = 455"
      ],
      "metadata": {
        "id": "40yDj7VCAbKq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates of fighter IDs\n",
        "fighter_info_df = fighter_info_concat.drop_duplicates(subset=['ID'])"
      ],
      "metadata": {
        "id": "-5-93Ib3CLPY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change anything with the ID of 2709 to be 455 since these are the same fighter\n",
        "fight_info_df.loc[fight_info_df['R_ID'] == 2709, 'R_ID'] = 455\n",
        "fight_info_df.loc[fight_info_df['B_ID'] == 2709, 'B_ID'] = 455\n",
        "fight_info_df.loc[fight_info_df['winner'] == 2709, 'winner'] = 455"
      ],
      "metadata": {
        "id": "pAbUJc8XC29m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start setting up the model"
      ],
      "metadata": {
        "id": "ctO7PN4aGccf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use label encoding because we have some text columns - fighter cols first\n",
        "fighter_info_df = fighter_info_df.copy()  # use to avoid warnings\n",
        "\n",
        "for col in fighter_info_df.select_dtypes(exclude=['number']).columns:\n",
        "  fighter_info_df[col] = LabelEncoder().fit_transform(fighter_info_df[col])\n",
        "  fighter_info_df[col] = fighter_info_df[col].astype(int)  # convert to integer\n",
        "\n",
        "# Label encoding for the fights\n",
        "fight_info_df = fight_info_df.copy()  # use to avoid warnings\n",
        "fight_info_df['winner'] = fight_info_df['winner'].astype(int)  # convert to integer so it doesn't get labeled\n",
        "\n",
        "for col in fight_info_df.select_dtypes(exclude=['number']).columns:\n",
        "  fight_info_df[col] = fight_info_df[col].astype(str)  # change to str - we can't have ints and str for the encoder\n",
        "  fight_info_df[col] = LabelEncoder().fit_transform(fight_info_df[col])\n",
        "  fight_info_df[col] = fight_info_df[col].astype(int)  # convert to integer"
      ],
      "metadata": {
        "id": "-lIStC2udLJv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect each fighter ID to a node and then specify which node is the fight winner\n",
        "fighter_id_to_node_idx = {id: idx for idx, id in enumerate(fighter_info_df['ID'])}\n",
        "fight_info_df['winner_node'] = fight_info_df['winner'].map(fighter_id_to_node_idx)"
      ],
      "metadata": {
        "id": "3tdue27suLD6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale node features and edge features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Node features into tensors - drop Fighter ID from node df because it isn't a feature\n",
        "node_features_scaled = scaler.fit_transform(fighter_info_df.drop('ID', axis=1).values)\n",
        "node_features = torch.tensor(node_features_scaled, dtype=torch.float)\n",
        "\n",
        "# Edge indices into tensors\n",
        "edge_index = torch.tensor([[fighter_id_to_node_idx[blue], fighter_id_to_node_idx[red]] for blue, red in zip(fight_info_df['B_ID'], fight_info_df['R_ID'])], dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Edge features to tensors\n",
        "fight_edge_cols = fight_info_df.columns[np.r_[2:6, 8:len(fight_info_df.columns)-1]]  # take out event ID, fight ID, blue ID, and red ID cols (not features)\n",
        "edge_features_scaled = scaler.fit_transform(fight_info_df[fight_edge_cols].values)\n",
        "edge_features = torch.tensor(edge_features_scaled, dtype=torch.float)\n",
        "\n",
        "# Edge labels for naming which node won\n",
        "edge_labels = torch.tensor(fight_info_df['winner_node'].values, dtype=torch.float)"
      ],
      "metadata": {
        "id": "OXZQ_3K9pi5B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a geometric object from PyTorch\n",
        "data = Data(\n",
        "  x=node_features,\n",
        "  edge_index=edge_index,\n",
        "  edge_attr=edge_features,\n",
        "  y=edge_labels)"
      ],
      "metadata": {
        "id": "iVfQqmjWq12C"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the GNN (Graph Neural Network) model\n",
        "class GNNModel(nn.Module):\n",
        "  def __init__(self, input_dim, edge_dim, hidden_dim, num_nodes):\n",
        "    super(GNNModel, self).__init__()\n",
        "    self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "    self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "    self.fc1 = nn.Linear(hidden_dim + edge_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, num_nodes)\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.relu(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.relu(x)\n",
        "\n",
        "    # Concatenate node embeddings with edge features\n",
        "    edge_embeddings = torch.cat([\n",
        "      x[data.edge_index[0]],  # node embeddings for source nodes\n",
        "      edge_attr], dim=1)\n",
        "\n",
        "    edge_embeddings = self.fc1(edge_embeddings)\n",
        "    edge_embeddings = torch.relu(edge_embeddings)\n",
        "    out = self.fc2(edge_embeddings)\n",
        "    return out"
      ],
      "metadata": {
        "id": "3wmIHrBVrqHY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the split transformation for train/test data\n",
        "split = RandomLinkSplit(\n",
        "  num_val=0.1,  # validation ratio\n",
        "  num_test=0.1,  # test ratio\n",
        "  is_undirected=True,  # graph is undirected\n",
        "  add_negative_train_samples=False)  # don't add negative samples to the training set\n",
        "\n",
        "# Apply the transformation\n",
        "train_data, val_data, test_data = split(data)\n",
        "\n",
        "# Change train_data.y to be an integer because it gives an error if it is a float\n",
        "train_data.y = train_data.y.long()"
      ],
      "metadata": {
        "id": "XVigTk3XrqKL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting optimizer, loss, and training the model thorugh epochs\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GNNModel(input_dim=node_features.shape[1], edge_dim=edge_features.shape[1],\n",
        "                 hidden_dim=16, num_nodes=len(fighter_info_df)).to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(200):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  out = model(train_data)\n",
        "  loss = criterion(out, train_data.y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if (epoch + 1) == 1 or (epoch + 1) % 10 == 0:\n",
        "    print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UrpiP8SyBoC",
        "outputId": "cd6cf673-6bfa-4b38-d8af-7c7cb70633b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.0279\n",
            "Epoch 10, Loss: 5.1316\n",
            "Epoch 20, Loss: 3.5316\n",
            "Epoch 30, Loss: 2.4470\n",
            "Epoch 40, Loss: 1.7132\n",
            "Epoch 50, Loss: 1.1635\n",
            "Epoch 60, Loss: 0.7405\n",
            "Epoch 70, Loss: 0.4569\n",
            "Epoch 80, Loss: 0.2772\n",
            "Epoch 90, Loss: 0.1710\n",
            "Epoch 100, Loss: 0.1090\n",
            "Epoch 110, Loss: 0.0727\n",
            "Epoch 120, Loss: 0.0508\n",
            "Epoch 130, Loss: 0.0369\n",
            "Epoch 140, Loss: 0.0279\n",
            "Epoch 150, Loss: 0.0220\n",
            "Epoch 160, Loss: 0.0178\n",
            "Epoch 170, Loss: 0.0148\n",
            "Epoch 180, Loss: 0.0126\n",
            "Epoch 190, Loss: 0.0108\n",
            "Epoch 200, Loss: 0.0094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  val_out = model(val_data)\n",
        "  val_preds = val_out.argmax(dim=1)\n",
        "  val_correct = (val_preds == val_data.y).sum().item()\n",
        "  val_acc = val_correct / val_data.y.size(0)\n",
        "  print(f'Validation Accuracy: {val_acc:.4f}')\n",
        "\n",
        "  test_out = model(test_data)\n",
        "  test_preds = test_out.argmax(dim=1)\n",
        "  test_correct = (test_preds == test_data.y).sum().item()\n",
        "  test_acc = test_correct / test_data.y.size(0)\n",
        "  print(f'Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnXY6roypjF2",
        "outputId": "81f344a5-1cae-410e-832b-4ed7141d3c09"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 1.0000\n",
            "Test Accuracy: 0.8816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looks like a problem with the validation accuracy - to go back and check"
      ],
      "metadata": {
        "id": "3GxXrLBwmpxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "akjTokuCperz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fOAkuIMvpeuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOfQltYgpexU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCZ40-rQpe0T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}